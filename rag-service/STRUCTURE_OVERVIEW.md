# CatalystAI RAG Service - Restructured Architecture

## üèóÔ∏è **New Architecture Overview**

The code has been restructured for better **performance**, **readability**, and **standards compliance**.

## üìÅ **Restructured Directory Layout**

```
rag-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ core/                          # Core infrastructure
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Core module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                 # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py             # Centralized exception handling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py                   # Base classes and interfaces
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                      # Business logic services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Service module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_service.py       # Document processing orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search_service.py         # Hybrid search implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py      # Embedding generation & caching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking_service.py       # Document chunking strategies
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ranking_service.py        # Result ranking & reranking
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ingestion_service.py      # Intelligent data ingestion
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # Data models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Model exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requests.py               # Request payload models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ responses.py              # Response payload models
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ parsers/                       # Document parsers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Parser exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_parser.py            # Base parser interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openapi_parser.py         # OpenAPI/Swagger parser
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graphql_parser.py         # GraphQL schema parser
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ soap_parser.py            # SOAP WSDL parser
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ markdown_parser.py        # Markdown documentation parser
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                       # LLM prompt templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Prompt exports
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api_identification.py     # API identification prompts
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                         # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Utility exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_processing.py        # Text processing utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validation.py             # Data validation utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py                # Performance metrics utilities
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # FastAPI application entry point
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ unit/                         # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/                  # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                     # Test data and fixtures
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ sample_data_collection.py     # Sample data generation
‚îÇ   ‚îî‚îÄ‚îÄ performance_testing.py        # Performance testing utilities
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ API.md                        # API documentation
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT.md                 # Deployment guide
‚îÇ   ‚îî‚îÄ‚îÄ DEVELOPMENT.md                # Development guide
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                   # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile                         # Container configuration
‚îú‚îÄ‚îÄ docker-compose.yml                 # Local development setup
‚îî‚îÄ‚îÄ README.md                          # Project overview
```

## üîß **Key Architectural Improvements**

### **1. Base Classes & Interfaces**

#### **BaseService Class**
```python
class BaseService(ABC, Generic[InputT, OutputT, ConfigT]):
    """Base class for all services with consistent interface"""
    
    async def initialize(self) -> None:
        """Initialize the service"""
        
    @async_timing_decorator
    async def execute(self, input_data: InputT) -> OutputT:
        """Execute with timing and error handling"""
        
    async def health_check(self) -> Dict[str, Any]:
        """Check service health"""
```

#### **BaseParser Class**
```python
class BaseParser(ABC, Generic[InputT, OutputT]):
    """Base class for document parsers with caching"""
    
    async def parse(self, content: str, metadata: Dict[str, Any]) -> OutputT:
        """Parse document content"""
        
    async def parse_with_caching(self, content: str, metadata: Dict[str, Any]) -> OutputT:
        """Parse with performance caching"""
```

### **2. Centralized Exception Handling**

#### **Exception Hierarchy**
```python
class CatalystAIException(Exception):
    """Base exception for all CatalystAI errors"""
    
class ValidationError(CatalystAIException):
    """Data validation failures"""
    
class ProcessingError(CatalystAIException):
    """Document processing failures"""
    
class SearchError(CatalystAIException):
    """Search operation failures"""
    
class EmbeddingError(CatalystAIException):
    """Embedding generation failures"""
```

### **3. Performance Optimizations**

#### **Async Timing Decorator**
```python
def async_timing_decorator(func):
    """Measure async function execution time"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        execution_time = time.time() - start_time
        return result
    return wrapper
```

#### **Retry Logic with Exponential Backoff**
```python
def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """Retry operations on failure with exponential backoff"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay * (2 ** attempt))
                    continue
            raise e
        return wrapper
    return decorator
```

#### **Intelligent Caching**
```python
class BaseParser:
    def __init__(self, name: str, supported_types: List[str]):
        self._cache = {}
        self._cache_ttl = 3600  # 1 hour
    
    async def parse_with_caching(self, content: str, metadata: Dict[str, Any]) -> OutputT:
        """Parse with intelligent caching for performance"""
        cache_key = self._get_cache_key(content, metadata)
        
        # Try cache first
        cached_result = self._get_from_cache(cache_key)
        if cached_result is not None:
            return cached_result
        
        # Parse and cache
        result = await self.parse(content, metadata)
        self._set_cache(cache_key, result)
        return result
```

### **4. Service Metrics & Monitoring**

#### **ServiceMetrics Class**
```python
@dataclass
class ServiceMetrics:
    """Metrics for service performance monitoring"""
    operation_name: str
    execution_time: float
    success: bool
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None
    timestamp: datetime = None
```

#### **Metrics Collection**
```python
class BaseService:
    def __init__(self, config: ConfigT):
        self.metrics: List[ServiceMetrics] = []
    
    def _record_metrics(self, success: bool, error_message: Optional[str] = None):
        """Record service execution metrics"""
        # Integrate with metrics system
        pass
    
    def get_metrics(self) -> List[ServiceMetrics]:
        """Get service performance metrics"""
        return self.metrics.copy()
```

## üöÄ **Performance Improvements**

### **1. Batch Processing**
```python
async def generate_embeddings_batch(self, texts: List[str], batch_size: int = 100):
    """Process embeddings in optimal batches"""
    if len(texts) <= batch_size:
        return await self._generate_batch_embeddings(texts)
    else:
        return await self._generate_batched_embeddings(texts, batch_size)
```

### **2. Concurrent Processing**
```python
async def _generate_batched_embeddings(self, texts: List[str], batch_size: int):
    """Process batches with controlled concurrency"""
    batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]
    
    # Control concurrency with semaphore
    semaphore = asyncio.Semaphore(self._max_concurrent_batches)
    
    async def process_batch(batch: List[str]):
        async with semaphore:
            return await self._generate_batch_embeddings(batch)
    
    # Process all batches concurrently
    batch_tasks = [process_batch(batch) for batch in batches]
    results = await asyncio.gather(*batch_tasks, return_exceptions=True)
    
    return self._process_batch_results(results)
```

### **3. Connection Pooling**
```python
class EmbeddingService:
    def __init__(self, config: Settings):
        self._models: Dict[str, Any] = {}
        self._batch_size = config.embedding_batch_size
        self._max_concurrent_batches = config.embedding_max_concurrent_batches
```

## üìä **Readability Improvements**

### **1. Clear Method Names**
```python
# Before: Unclear method names
async def process(self, doc, meta):
    # ...

# After: Clear, descriptive method names
async def process_document(self, document: Document, metadata: DocumentMetadata):
    # ...
```

### **2. Type Hints Throughout**
```python
from typing import List, Dict, Any, Optional, Tuple

async def search_apis(
    self,
    query: str,
    filters: Optional[SearchFilter] = None,
    limit: int = 10
) -> SearchResponse:
    # ...
```

### **3. Comprehensive Documentation**
```python
class SearchService(BaseService[SearchRequest, SearchResponse, Settings]):
    """
    High-performance hybrid search service combining vector and keyword search
    
    Features:
    - Vector similarity search
    - Keyword-based filtering
    - SOLAR-style ranking
    - Result reranking with cross-encoders
    - Streaming search results
    """
```

### **4. Consistent Error Handling**
```python
try:
    result = await self._execute_search(query, filters, limit)
    return result
except Exception as e:
    logger.error(f"Search operation failed: {str(e)}")
    raise SearchError(f"Search failed: {str(e)}", query, filters)
```

## üéØ **Standards Compliance**

### **1. PEP 8 Compliance**
- Consistent naming conventions
- Proper line lengths
- Clear import organization

### **2. Type Safety**
- Full type hints throughout
- Generic type support
- Optional type handling

### **3. Async/Await Best Practices**
- Proper async context management
- Exception handling in async code
- Resource cleanup in async functions

### **4. Error Handling Standards**
- Custom exception hierarchy
- Consistent error messages
- Proper error logging

## üîÑ **Migration Benefits**

### **Before (Old Structure)**
- ‚ùå Monolithic services
- ‚ùå No error handling
- ‚ùå No performance monitoring
- ‚ùå No caching
- ‚ùå Inconsistent interfaces
- ‚ùå No type hints

### **After (New Structure)**
- ‚úÖ Modular, focused services
- ‚úÖ Comprehensive error handling
- ‚úÖ Performance metrics & monitoring
- ‚úÖ Intelligent caching
- ‚úÖ Consistent interfaces
- ‚úÖ Full type safety
- ‚úÖ Performance optimizations
- ‚úÖ Better testability

## üöÄ **Next Steps for Implementation**

1. **Implement Base Classes**: Create the foundation classes
2. **Refactor Services**: Update existing services to use new base classes
3. **Add Exception Handling**: Implement centralized error handling
4. **Add Performance Monitoring**: Integrate metrics collection
5. **Optimize Critical Paths**: Focus on search and embedding performance
6. **Add Comprehensive Tests**: Ensure reliability and performance
7. **Document APIs**: Create comprehensive API documentation

This restructured architecture provides a solid foundation for scaling, maintaining, and extending the CatalystAI RAG service while following Python best practices and performance optimization techniques.

